---
title: "Covid-19 Stats for Denmark"
date: 2022-01-13
output:
  html_document:
    toc: true
---

## Strategy

Data processing is best handled by writing a program which processes the data, rather than using interactive
methods by hand. The reason is underlying data changes dynamically over time, but the *program* stays the
same. This means we can simply re-run the program whenever data changes and get new visualizations.

This visualization uses *R* which is a language mostly for statistical processing. It also has a very strong
visualization side, and this is used by SSI in Denmark for their reporting. The original compartmental models
by SSI for Covid-19, used for predictions, also used *R*.

For our work here, *R* is a good choice because it has lots of tooling for working with tables of data. And
SSI provide their data in tabular format.

## Initial setup

To process data sets from SSI, we'll need some packages for doing so. We'll
load `tidyverse`, and `lubridate`.

The `lubridate` package empowers our *R* system with better handling of dates and timestamps. The `tidyverse`
package loads a slew of other packages for *R*. These empower our system to be more like a *functional*
programming language, which I tend to like working in.

You can grab SSI's data from [their homepage](https://covid19.ssi.dk/overvagningsdata/download-fil-med-overvaagningdata)

```{r setup, include = TRUE, echo = TRUE, message = FALSE}
library(tidyverse)
library(lubridate)
```

SSI's data is in a zip file. We unpack this zip file into a directory of the
general form `YYYY-MM-DD`. Lets set up a name for the current directory we
want to grab data from

```{r constants}
date <- "2022-01-13"
```

## Ingesting data

SSIs data are in "CSV" files. The CSV format isn't well specified, and the variant
used by SSI is a variant in which the `;` character is used as a separator. This is
relatively common in countries which uses the `,` as a separator in numbers, in order
to avoid conflicts. R's `readr` package have a way to handle this particular CSV variant.

Furthermore, the files contain danish characters. They are encoded in the ISO8859-1(5)
format, so we'll have to do something about this. The obvious way is to turn the
encoding into UTF-8, which is the modern encoding of Unicode. Once transformed into
UTF-8, we can read the data into R.

We'll capture this conversion into a function `read_data`. It uses
[iconv](https://en.wikipedia.org/wiki/Iconv) to convert between encodings. The function
also allows us to designate the types of the columns in the file we are trying to read.

```{r read_function}
read_data <- function(f, col_types) {
    raw <- readBin(f, "raw", n = file.size(f))
    x_utf8 <- iconv(list(raw), from = "ISO-8859-1", to = "UTF-8", toRaw = TRUE)[[1]]

    # CSV variant 2 uses ; as the separator, among other adaptations
    res <- read_csv2(x_utf8, col_types=col_types)
    return(res)
}
```

### Key Numbers

SSI provides a file with key numbers from the Covid-19 data gathered by them. This file is updated 5
days a week. We already unzipped the file in a directory, so lets expand our `date` constant and get a
file name

```{r}
file <- sprintf("./data/%s/Regionalt_DB/03_bekraeftede_tilfaelde_doede_indlagte_pr_dag_pr_koen.csv", date)
```

We can read this file via our function. It will return a so-called `tibble` which is a table, or data frame,
of the data in the file. We also provide initial types for each of the columns. In CSV, data is untyped.
We would like to add type information to columns because it simplifies our later plotting. Many tools in R
know how to handle data by its type. Hence, if we have the right type, tools will naturally understand how
to process the data at hand.

In the following we use the following types:

* `col_date()` is a date, with no particular timestamp.
* `col_double()` is a floating point number. Because the numbers are "smallish", using a double float for this carries enough precision for the integers we have.
* `col_factor()` is used the define factor values. These are small (discrete) sets of values, in this case the different Regions of denmark.

```{r}
data <- read_data(file, col_types=cols('Region' = col_factor(),
                                       'Prøvetagningsdato' = col_date(),
                                       'Køn' = col_factor(),
                                       'Bekræftede tilfælde' = col_double(),
                                       'Døde' = col_double(),
                                       'Indlæggelser' = col_double()
                                      ))
data
```

We certainly don't want to work with danish-named columns. Rather, we want small
descriptive names which are easy to type. We send our dataset through a `rename`
pass for this.

And while we are here, lets also limit ourselves to the columns we are interested
in. There are some cumulative columns in the dataset, but we are not going to be
interested in those. So we select the columns we care about.

```{r key_rename}
data <- data %>% rename(region = 'Region',
                        date = 'Prøvetagningsdato',
                        gender = 'Køn', # This might be wrong, because it could also be 'sex'. However, we are going to aggregate it
                        cases = 'Bekræftede tilfælde',
                        deaths = 'Døde',
                        hospitalizations = 'Indlæggelser')

# Cut the cumulative columns away
data <- data %>% select(region, date, gender, cases, deaths, hospitalizations)
data
```

More data handling. We are interested in somewhat recent data. Covid-19 has been around
for a while. We are mostly interested in the recent development which is that Delta was dominant,
and Omicron came into the space. Let's put a low-end cutoff down:

```{r}
lo_cutoff <- '2021-09-01'
```

The hi-end of that cutoff, we set to two days before the maximal date in our data set

```{r}
hi_cutoff <- max(data$date) - days(2)
```

Rationale: when you have a reported number in the news, it's generally a number from the
cumulative count. The actual date of testing is often lagging by 24h to 48h. We are interested
in getting the right test-date, even if it means we have a 2 days lag. Hence, we assume
that recent data are still "forming". A typical example is that the count for the current
date is very close to 0, as no tests have come in yet. In 2-3 days time, this number rises
to the right value, as data is retroactively updated.

Filtering the data set is easy:

```{r summary}
data <- data %>% filter(date >= lo_cutoff, date < hi_cutoff)

# Put this into the summary
summary <- data
summary
```

### Weekly key data split by age

As in the case with the general data, we can define the file of interest

```{r}
file <- sprintf("./data/%s/Regionalt_DB/18_fnkt_alder_uge_testede_positive_nyindlagte.csv", date)
```

We can reuse our data reader from before.

```{r}
data <- read_data(file, col_types=cols('Uge' = col_character(), # This will need fixing later
                                       'Aldersgruppe' = col_factor(),
                                       'Testede pr. 100.000 borgere' = col_double(),
                                       'Positive pr. 100.000 borgere' = col_double(),
                                       'Nyindlagte pr. 100.000 borgere' = col_double(),
                                       'Antal testede' = col_double(),
                                       'Antal positive' = col_double()
                                      ))
```

First, let's do the same thing as before. Rename the columns to something more amenable
to further handling

```{r}
data <- data %>% rename(week = 'Uge',
                        ageGroup = 'Aldersgruppe',
                        tested_100k = 'Testede pr. 100.000 borgere',
                        cases_100k = 'Positive pr. 100.000 borgere',
                        hospitalized_100k = 'Nyindlagte pr. 100.000 borgere',
                        tested = 'Antal testede',
                        cases = 'Antal positive')
data
```

Take a look at the `week` column. It reports a year, and a week number. We'll need to handle this,
by converting this into a date. We'll do that by defining a fixup function. If we have a string such
as `2020-W04`, it means the 4th week of 2020. But to get a date, we need a day inside the week to use
as the day-of-week. So first, we turn the string into `2020-W04-1`, then we send it through `strptime()`,
which is a general time-parsing function.

```{r}
fixup_week <- function(s) {
    # For strptime to do its work correctly, it must know a day of the week. Here, we
    # use the 1st day of the week as a anchoring point, but in principle any day could
    # have been used.
    x <- sprintf("%s-1", s)
    res <- strptime(x, format="%Y-W%W-%u")
    return(as.POSIXct(res))
}
```

With the function defined, we can `mutate` our data set by the fixup, setting each value in the table
to be the fixup'ed value. While here, we can also cut off the older values since we are mostly interested
in the recent data, as in the above example.

```{r, warning = FALSE}
# Apply this to the data set
data <- data %>% mutate(week = fixup_week(week))
data <- data %>% filter(week >= lo_cutoff)
```

Finally, lets use a good name for this dataset (tibble):

```{r}
weekly <- data
```

## Plots

### General key data plotting

First, lets analyze the country-wide data set. Because data is given by each region,
we must first summarize the data by summing the data from each region per day. This
means we group by the `date` and then sum

```{r}
# Group by date, so we can get rid of region/gender
country <- summary %>% group_by(date)
# Summarize the data by counting
country <- country %>% summarize(cases = sum(cases),
                                 deaths = sum(deaths),
                                 hospitalizations = sum(hospitalizations))
```

We also want a lag-column. That is, for each date, we want the count from the
day preceding it. This allows us to compute the change for each day.

```{r}
# Create a lag column for cases
country <- country %>% mutate(previous_cases = lag(cases, order_by=date),
                              weekday = lubridate::wday(date, label=TRUE))
```

At this point, we have readied our data, and can start plotting. First, lets plot
the number of cases we have in Denmark, and supply a trend-line for the cases

```{r}
plot_country <- function(p, title, subtitle) {
    p + geom_point(aes(color = weekday), size=3) +
        geom_smooth(method = 'loess', span = 0.3) +
        scale_colour_brewer(palette="Set2") +
        labs(title = title, subtitle = subtitle)
}

# Write to a file
p <- ggplot(country, aes(x=date, y=cases))
plot_country(p, "Trendline for Covid-19 cases in Denmark", "Source: ssi.dk")
```

```
# Write to a file
p <- ggplot(country, aes(x=date, y=hospitalizations))
plot_country(p, "hospitalizations.png", "Covid-19: new hospitalizations in Denmark", "Source: ssi.dk")

p <- ggplot(country, aes(x=date, y=deaths))
plot_country(p, "deaths.png", "Covid-19: new deaths in Denmark", "Source: ssi.dk")

# Plot per weekday
plot_day_of_week <- function(p, filename, title, subtitle) {
    p + geom_point() +
        geom_jitter() +
        scale_colour_brewer(palette="Set1") +
        stat_boxplot(aes(fill=weekday, color=weekday), alpha=0.3) +
        labs(title = title, subtitle = subtitle)

    ggsave(filename, height=9, width=16, dpi=120)
}

p <- ggplot(country, aes(x=weekday, y=(cases - previous_cases)))
plot_day_of_week(p, "cases_weekday.png", "New Covid-19 cases in Denmark, day of week (2021-09-01 to 2022-01-10)", "Source: ssi.dk")

# Lagged data computes the difference to the day before.
plot_country_lag <- function(p, filename, title, subtitle) {
    p + geom_point(size=3) +
        scale_colour_brewer(palette="Set2") +
        labs(title = title, subtitle = subtitle)

    ggsave(filename, height=9, width=16, dpi=120)
}

p <- ggplot(country, aes(x=date, y=(cases - previous_cases), color=weekday))
plot_country_lag(p, "cases_lag.png", "Covid-19 cases change per day, Denmark", "Source: ssi.dk")

### REGIONAL DATA
## Generally follows the same structure as for the country-wide cases.

regions <- summary %>% group_by(date, region)
regions <- regions %>% summarize(cases = sum(cases), deaths = sum(deaths), hospitalizations = sum(hospitalizations))
regions <- regions %>% mutate(weekday = lubridate::wday(date, label=TRUE), order_by=date)

plot_regions <- function(p, filename, title, subtitle) {
    p + geom_point(aes(color=region), size=2) +
        geom_smooth(method = 'loess', span = 0.3) +
        facet_grid(rows=vars(region)) +
        scale_colour_brewer(palette="Set2") +
        labs(title = title, subtitle = subtitle)

    ggsave(filename, height=9, width=16, dpi=120)
}

p <- ggplot(regions, aes(x=date, y=cases))
plot_regions(p, "regions.png", "Covid-19 cases in Denmark, per region", "Source: ssi.dk")

plot_age_cases <- function(p, filename, title, subtitle) {
    p + geom_raster() +
        scale_fill_continuous(type = "viridis") +
        labs(title = title, subtitle = subtitle)

    ggsave(filename, height=9, width=16, dpi=120)
}

p <- ggplot(weekly, aes(x=week, y=ageGroup, fill=cases_100k))
plot_age_cases(p, "weekly_age_cases.png", "Covid-19 cases per 100k in Denmark, by age group", "Source: ssi.dk")

p <- ggplot(weekly, aes(x=week, y=ageGroup, fill=tested_100k))
plot_age_cases(p, "weekly_age_tested.png", "Covid-19 tests per 100k in Denmark, by age group", "Source: ssi.dk")
```