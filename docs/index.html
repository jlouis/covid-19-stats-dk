<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />



<meta name="date" content="2022-03-11" />

<title>Covid-19 Stats for Denmark</title>

<script src="site_libs/header-attrs-2.11/header-attrs.js"></script>
<script src="site_libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/bootstrap.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<style>h1 {font-size: 34px;}
       h1.title {font-size: 38px;}
       h2 {font-size: 30px;}
       h3 {font-size: 24px;}
       h4 {font-size: 18px;}
       h5 {font-size: 16px;}
       h6 {font-size: 12px;}
       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}
       pre:not([class]) { background-color: white }</style>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>

<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>

<style type="text/css">code{white-space: pre;}</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>








<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
pre code {
  padding: 0;
}
</style>


<style type="text/css">
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #adb5bd;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script type="text/javascript">
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.tab('show');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');

  // Navbar adjustments
  var navHeight = $(".navbar").first().height() + 15;
  var style = document.createElement('style');
  var pt = "padding-top: " + navHeight + "px; ";
  var mt = "margin-top: -" + navHeight + "px; ";
  var css = "";
  // offset scroll position for anchor links (for fixed navbar)
  for (var i = 1; i <= 6; i++) {
    css += ".section h" + i + "{ " + pt + mt + "}\n";
  }
  style.innerHTML = "body {" + pt + "padding-bottom: 40px; }\n" + css;
  document.head.appendChild(style);
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->




</head>

<body>


<div class="container-fluid main-container">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">Covid-19 Stats for Denmark</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">Home</a>
</li>
<li>
  <a href="core.html">New development</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div id="header">



<h1 class="title toc-ignore">Covid-19 Stats for Denmark</h1>
<h4 class="date">2022-03-11</h4>

</div>

<div id="TOC">
<ul>
<li><a href="#strategy">Strategy</a></li>
<li><a href="#initial-setup">Initial setup</a></li>
<li><a href="#ingesting-data">Ingesting data</a>
<ul>
<li><a href="#daily-key-figures">Daily key figures</a></li>
<li><a href="#weekly-key-figures-split-by-age">Weekly key figures split by age</a></li>
<li><a href="#data-for-muncipalities">Data for muncipalities</a></li>
</ul></li>
<li><a href="#country-wide-data">Country-wide data</a>
<ul>
<li><a href="#country-wide-visualizations">Country-wide visualizations</a></li>
</ul></li>
<li><a href="#regional-data">Regional data</a>
<ul>
<li><a href="#regional-visualizations">Regional visualizations</a></li>
</ul></li>
<li><a href="#weekly-data">Weekly data</a>
<ul>
<li><a href="#visualizations">Visualizations</a></li>
</ul></li>
<li><a href="#muncipality-data">Muncipality data</a>
<ul>
<li><a href="#analyzing-infections-over-population-counts">Analyzing infections over population counts</a></li>
</ul></li>
</ul>
</div>

<div id="strategy" class="section level2">
<h2>Strategy</h2>
<p>Data processing is best handled by writing a program which processes the data, rather than using interactive methods by hand. The reason is underlying data changes dynamically over time, but the <em>program</em> stays the same. This means we can simply re-run the program whenever data changes and get new visualizations.</p>
<p>This visualization uses <em>R</em> which is a language mostly for statistical processing. It also has a very strong visualization side, and this is used by SSI in Denmark for their reporting. The original compartmental models by SSI for Covid-19, used for predictions, also used <em>R</em>.</p>
<p>For our work here, <em>R</em> is a good choice because it has lots of tooling for working with tables of data. And SSI provide their data in tabular format.</p>
</div>
<div id="initial-setup" class="section level2">
<h2>Initial setup</h2>
<p>To process data sets from SSI, we’ll need some packages for doing so. We’ll load <code>tidyverse</code>, and <code>lubridate</code>.</p>
<p>The <code>lubridate</code> package empowers our <em>R</em> system with better handling of dates and timestamps. The <code>tidyverse</code> package loads a slew of other packages for <em>R</em>. These empower our system to be more like a <em>functional</em> programming language, which I tend to like working in.</p>
<p>You can grab SSI’s data from <a href="https://covid19.ssi.dk/overvagningsdata/download-fil-med-overvaagningdata">their homepage</a></p>
<pre class="r"><code>library(tidyverse)
library(lubridate)</code></pre>
<p>SSI’s data is in a zip file. We unpack this zip file into a directory of the general form <code>YYYY-MM-DD</code>. Lets set up a name for the current directory we want to grab data from</p>
<pre class="r"><code>date &lt;- &quot;2022-03-11&quot;</code></pre>
</div>
<div id="ingesting-data" class="section level2">
<h2>Ingesting data</h2>
<p>The overall strategy follows a 3-step process:</p>
<ul>
<li><em>Parse</em> the incoming data, providing a proper interpretation of what it means.</li>
<li><em>Transform</em> the data, making it amenable for data-visualization.</li>
<li><em>Visualize</em> the data, aiding the understanding of patterns, evaluations, and structure.</li>
</ul>
<p>SSIs data are in “CSV” files. The CSV format isn’t generally well specified, and the variant used by SSI is one in which the <code>;</code> character is used as a separator. This is relatively common in countries using the <code>,</code> as a separator in numbers. R’s <code>readr</code> package, loaded by <code>tidyverse</code>, have a way to handle this particular CSV variant.</p>
<p>Furthermore, the files contain Danish characters. They are encoded in the ISO8859-1(5) format, so we’ll have to do something about this. The obvious way is to turn the encoding into UTF-8, which is the modern encoding of Unicode.</p>
<p>We’ll capture this conversion into a function <code>read_data</code>. It uses <a href="https://en.wikipedia.org/wiki/Iconv">iconv</a> to convert between encodings. The function also allows us to designate the types of the columns in the file we are trying to read.</p>
<pre class="r"><code>read_data &lt;- function(f, col_types) {
    raw &lt;- readBin(f, &quot;raw&quot;, n = file.size(f))
    x_utf8 &lt;- iconv(list(raw), from = &quot;ISO-8859-1&quot;, to = &quot;UTF-8&quot;, toRaw = TRUE)[[1]]

    # CSV variant 2 uses ; as the separator, among other adaptations
    res &lt;- read_csv2(x_utf8, col_types=col_types)
    return(res)
}</code></pre>
<div id="daily-key-figures" class="section level3">
<h3>Daily key figures</h3>
<p>SSI provides a file with key figures. This file is updated 5 days a week. Since we already have set a target date, we can compute the file with key figures in it by substitution</p>
<pre class="r"><code>file &lt;- sprintf(&quot;./data/%s/Regionalt_DB/03_bekraeftede_tilfaelde_doede_indlagte_pr_dag_pr_koen.csv&quot;, date)</code></pre>
<p>We can read this file via our function. It will return a so-called <code>tibble</code> which is a table, or data frame, of the data in the file. We also provide initial types for each of the columns, because CSV data is untyped.</p>
<p>We would like to add type information to columns because it simplifies our later plotting. Many tools in R know how to vary it’s handling, based on the type.</p>
<p>In the following we use the following types:</p>
<ul>
<li><code>col_date()</code> is a date, with no particular timestamp.</li>
<li><code>col_double()</code> is a floating point number. This allows parses of numbers in general, while still handling integers adequately.</li>
<li><code>col_factor()</code> is used the define factor values. These are small (discrete) sets of values, in this case the different Regions of Denmark.</li>
</ul>
<pre class="r"><code>data &lt;- read_data(file, col_types=cols(&#39;Region&#39; = col_factor(),
                                       &#39;Prøvetagningsdato&#39; = col_date(),
                                       &#39;Køn&#39; = col_factor(),
                                       &#39;Bekræftede tilfælde i alt&#39; = col_double(),
                                       &#39;Døde&#39; = col_double(),
                                       &#39;Indlæggelser&#39; = col_double()
                                      ))</code></pre>
<pre><code>## ℹ Using &quot;&#39;,&#39;&quot; as decimal and &quot;&#39;.&#39;&quot; as grouping mark. Use `read_delim()` for more control.</code></pre>
<pre class="r"><code>data</code></pre>
<pre><code>## # A tibble: 7,095 × 9
##    Region      Prøvetagningsdato Køn   `Bekræftede tilfælde…`  Døde Indlæggelser
##    &lt;fct&gt;       &lt;date&gt;            &lt;fct&gt;                  &lt;dbl&gt; &lt;dbl&gt;        &lt;dbl&gt;
##  1 Sjælland    2020-02-26        M                          1     0            0
##  2 Hovedstaden 2020-02-27        M                          1     0            0
##  3 Midtjylland 2020-02-28        M                          1     0            0
##  4 Hovedstaden 2020-03-01        M                          1     0            1
##  5 Hovedstaden 2020-03-02        M                          2     0            1
##  6 Sjælland    2020-03-02        M                          1     0            0
##  7 Syddanmark  2020-03-02        M                          1     0            0
##  8 Hovedstaden 2020-03-03        F                          1     0            0
##  9 Hovedstaden 2020-03-03        M                          3     0            1
## 10 Hovedstaden 2020-03-04        M                          2     0            0
## # … with 7,085 more rows, and 3 more variables: `Kummuleret antal døde` &lt;dbl&gt;,
## #   `Kummuleret antal bekræftede tilfælde` &lt;dbl&gt;,
## #   `Kummuleret antal indlæggelser` &lt;dbl&gt;</code></pre>
<p>We certainly don’t want to work with danish-named columns. Rather, we want small descriptive names which are easy to type. We send our dataset through a <code>rename</code> pass for this.</p>
<p>And while we are here, lets also limit ourselves to the columns we are interested in. There are some cumulative columns in the dataset, but we are not going to be interested in those. So we select the columns we care about.</p>
<pre class="r"><code>data &lt;- data %&gt;% rename(region = &#39;Region&#39;,
                        date = &#39;Prøvetagningsdato&#39;,
                        gender = &#39;Køn&#39;, # This might be wrong, because it could also be &#39;sex&#39;. However, we are going to aggregate it
                        cases = &#39;Bekræftede tilfælde i alt&#39;,
                        deaths = &#39;Døde&#39;,
                        hospitalizations = &#39;Indlæggelser&#39;)

# Cut the cumulative columns away
data &lt;- data %&gt;% select(region, date, gender, cases, deaths, hospitalizations)
data</code></pre>
<pre><code>## # A tibble: 7,095 × 6
##    region      date       gender cases deaths hospitalizations
##    &lt;fct&gt;       &lt;date&gt;     &lt;fct&gt;  &lt;dbl&gt;  &lt;dbl&gt;            &lt;dbl&gt;
##  1 Sjælland    2020-02-26 M          1      0                0
##  2 Hovedstaden 2020-02-27 M          1      0                0
##  3 Midtjylland 2020-02-28 M          1      0                0
##  4 Hovedstaden 2020-03-01 M          1      0                1
##  5 Hovedstaden 2020-03-02 M          2      0                1
##  6 Sjælland    2020-03-02 M          1      0                0
##  7 Syddanmark  2020-03-02 M          1      0                0
##  8 Hovedstaden 2020-03-03 F          1      0                0
##  9 Hovedstaden 2020-03-03 M          3      0                1
## 10 Hovedstaden 2020-03-04 M          2      0                0
## # … with 7,085 more rows</code></pre>
<p>Provide a low cut-off. We are interested in the recent period with Omicron, rather than the full duration of Covid-19.</p>
<pre class="r"><code>lo_cutoff &lt;- &#39;2021-09-01&#39;</code></pre>
<p>The high end of that cutoff, we set to two days before the maximal date in our data set</p>
<pre class="r"><code>hi_cutoff &lt;- max(data$date) - days(2)</code></pre>
<p>Rationale: News outlets generally report a cumulative count increase . The actual date of testing is often lagging by 24h to 48h. We are interested in getting the right test-date, even if it means we have a 2 days lag. Hence, we assume that recent data are still “forming”.</p>
<p>A typical example is that the count for the current date is very close to 0, as no tests have come in yet. In 2-3 days time, this number rises to the right value, as data is retroactively updated.</p>
<p>Using the cumulative count means that the test date is being moved to some other date, and this will skew any kind of trend-line attempt.</p>
<p>Filtering the data set is easy:</p>
<pre class="r"><code>data &lt;- data %&gt;% filter(date &gt;= lo_cutoff, date &lt; hi_cutoff)

# Put this into the summary
summary &lt;- data
summary</code></pre>
<pre><code>## # A tibble: 1,890 × 6
##    region      date       gender cases deaths hospitalizations
##    &lt;fct&gt;       &lt;date&gt;     &lt;fct&gt;  &lt;dbl&gt;  &lt;dbl&gt;            &lt;dbl&gt;
##  1 Hovedstaden 2021-09-01 F        215      0                7
##  2 Midtjylland 2021-09-01 F         66      0                0
##  3 Nordjylland 2021-09-01 F         22      0                4
##  4 Sjælland    2021-09-01 F         43      0                0
##  5 Syddanmark  2021-09-01 F         46      0                1
##  6 Hovedstaden 2021-09-01 M        185      2                8
##  7 Midtjylland 2021-09-01 M         49      0                1
##  8 Nordjylland 2021-09-01 M         16      1                2
##  9 Sjælland    2021-09-01 M         39      0                3
## 10 Syddanmark  2021-09-01 M         41      0                1
## # … with 1,880 more rows</code></pre>
</div>
<div id="weekly-key-figures-split-by-age" class="section level3">
<h3>Weekly key figures split by age</h3>
<p>As in the case with the general data, we can define the file of interest</p>
<pre class="r"><code>file &lt;- sprintf(&quot;./data/%s/Regionalt_DB/18_fnkt_alder_uge_testede_positive_nyindlagte.csv&quot;, date)</code></pre>
<p>We can reuse our data reader from before.</p>
<pre class="r"><code>data &lt;- read_data(file, col_types=cols(&#39;Uge&#39; = col_character(), # This will need fixing later
                                       &#39;Aldersgruppe&#39; = col_factor(),
                                       &#39;Testede pr. 100.000 borgere&#39; = col_double(),
                                       &#39;Positive pr. 100.000 borgere&#39; = col_double(),
                                       &#39;Nyindlagte pr. 100.000 borgere&#39; = col_double(),
                                       &#39;Antal testede&#39; = col_double(),
                                       &#39;Antal positive&#39; = col_double()
                                      ))</code></pre>
<pre><code>## ℹ Using &quot;&#39;,&#39;&quot; as decimal and &quot;&#39;.&#39;&quot; as grouping mark. Use `read_delim()` for more control.</code></pre>
<p>Rename the columns to something more amenable to further handling</p>
<pre class="r"><code>data &lt;- data %&gt;% rename(week = &#39;Uge&#39;,
                        ageGroup = &#39;Aldersgruppe&#39;,
                        tested_100k = &#39;Testede pr. 100.000 borgere&#39;,
                        cases_100k = &#39;Positive pr. 100.000 borgere&#39;,
                        hospitalized_100k = &#39;Nyindlagte pr. 100.000 borgere&#39;,
                        tested = &#39;Antal testede&#39;,
                        cases = &#39;Antal positive&#39;)
data</code></pre>
<pre><code>## # A tibble: 967 × 7
##    week     ageGroup tested_100k cases_100k hospitalized_100k tested cases
##    &lt;chr&gt;    &lt;fct&gt;          &lt;dbl&gt;      &lt;dbl&gt;             &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;
##  1 2020-W04 00-02              0          0                 0      0     0
##  2 2020-W04 03-05              0          0                 0      0     0
##  3 2020-W04 06-11              0          0                 0      0     0
##  4 2020-W04 12-15              0          0                 0      0     0
##  5 2020-W04 16-19              0          0                 0      0     0
##  6 2020-W04 20-39              0          0                 0      0     0
##  7 2020-W04 40-64              0          0                 0      0     0
##  8 2020-W04 65-79              0          0                 0      0     0
##  9 2020-W04 80+                0          0                 0      0     0
## 10 2020-W05 65-79              0          0                 0      1     0
## # … with 957 more rows</code></pre>
<p>Take a look at the <code>week</code> column. It reports a year, and a week number. We’ll need to handle this, by converting this into a date. We’ll do that by defining a fixup function. If we have a string such as <code>2020-W04</code>, it means the 4th week of 2020. To get a date, we need a day inside the week to use as the day-of-week. So we turn the string into <code>2020-W04-1</code>, then send it through <code>strptime()</code>, a general time-parsing function.</p>
<pre class="r"><code>fixup_week &lt;- function(s) {
    # For strptime to do its work correctly, it must know a day of the week. Here, we
    # use the 1st day of the week as a anchoring point, but in principle any day could
    # have been used.
    x &lt;- sprintf(&quot;%s-1&quot;, s)
    res &lt;- strptime(x, format=&quot;%Y-W%W-%u&quot;)
    return(as.POSIXct(res))
}</code></pre>
<p>With the function defined, we can <code>mutate</code> our data set by the fixup, setting each value in the table to be the fixup’ed value. While here, also cut off the older values since we are mostly interested in the recent data.</p>
<pre class="r"><code>lo_cutoff &lt;- &quot;2021-11-01&quot;

# Apply this to the data set
data &lt;- data %&gt;% mutate(week = fixup_week(week))
data &lt;- data %&gt;% filter(week &gt;= lo_cutoff)</code></pre>
<p>Finally, lets use a good name for this dataset (tibble):</p>
<pre class="r"><code>weekly &lt;- data</code></pre>
</div>
<div id="data-for-muncipalities" class="section level3">
<h3>Data for muncipalities</h3>
<p>The munciplality data is in a seperate file:</p>
<pre class="r"><code>file &lt;- sprintf(&quot;./data/%s/Kommunalt_DB/10_Kommune_kort.csv&quot;, date)</code></pre>
<p>This needs to be read, like the other data sets</p>
<pre class="r"><code>data &lt;- read_data(file, col_types=cols(&#39;Kommune&#39; = col_double(), # This will need fixing later
                                       &#39;Kommunenavn&#39; = col_factor(),
                                       &#39;Bekræftede tilfælde i alt&#39; = col_double(),
                                       &#39;Incidens&#39; = col_double(),
                                       &#39;Bekræftede tilfælde i alt de seneste 7 dage&#39; = col_double(),
                                       &#39;Incidens de seneste 7 dage&#39; = col_double(),
                                       &#39;Antal testede personer&#39; = col_double(),
                                       &#39;Testestede pr. 100.000&#39; = col_double(),
                                       &#39;Testede de seneste 7 dage&#39; = col_double(),
                                       &#39;Testede pr. 100.000 de seneste 7 dage&#39; = col_double(),
                                       &#39;Antal borgere&#39; = col_double()
                                      ))</code></pre>
<pre><code>## ℹ Using &quot;&#39;,&#39;&quot; as decimal and &quot;&#39;.&#39;&quot; as grouping mark. Use `read_delim()` for more control.</code></pre>
<p>And like before, this needs renaming</p>
<pre class="r"><code>data &lt;- data %&gt;% rename(lau1 = &#39;Kommune&#39;,
                        name = &#39;Kommunenavn&#39;,
                        incidence = &#39;Incidens de seneste 7 dage&#39;,
                        cases = &#39;Bekræftede tilfælde i alt de seneste 7 dage&#39;,
                        tested = &#39;Antal testede personer&#39;,
                        tested_100k = &#39;Testestede pr. 100.000&#39;,
                        tested_1w = &#39;Testede de seneste 7 dage&#39;,
                        tested_100k_1w = &#39;Testede pr. 100.000 de seneste 7 dage&#39;,
                        population = &#39;Antal borgere&#39;,
                        )
data</code></pre>
<pre><code>## # A tibble: 99 × 11
##     lau1 name       `Bekræftede ti…` Incidens cases incidence tested tested_100k
##    &lt;dbl&gt; &lt;fct&gt;                 &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;  &lt;dbl&gt;       &lt;dbl&gt;
##  1   411 &quot;&quot;                        0       NA     0        0      93      102000
##  2   101 &quot;Københav…           357777    55753  7189     1120  658962      103000
##  3   147 &quot;Frederik…            55149    53402  1331     1289  112596      109000
##  4   151 &quot;Ballerup&quot;            26562    53893   724     1469   50263      102000
##  5   153 &quot;Brøndby&quot;             20196    56594   355      995.  36327      102000
##  6   155 &quot;Dragør&quot;               7691    52779   182     1249   14597      100000
##  7   157 &quot;Gentofte&quot;            37914    51263   925     1251   76344      103000
##  8   159 &quot;Gladsaxe&quot;            37470    54173   894     1293   72390      105000
##  9   161 &quot;Glostrup&quot;            12746    54421   265     1131   24495      105000
## 10   163 &quot;Herlev&quot;              16345    56777   385     1337   29894      104000
## # … with 89 more rows, and 3 more variables: tested_1w &lt;dbl&gt;,
## #   tested_100k_1w &lt;dbl&gt;, population &lt;dbl&gt;</code></pre>
<pre class="r"><code>muncipalities &lt;- data</code></pre>
</div>
</div>
<div id="country-wide-data" class="section level2">
<h2>Country-wide data</h2>
<p>Let’s analyze the country-wide data set. Because data is given by each region, we must first summarize the data by summing the data from each region per day. This means we group by the <code>date</code> and then sum</p>
<pre class="r"><code># Group by date, so we can get rid of region/gender
country &lt;- summary %&gt;%
    group_by(date) %&gt;%
    summarize(cases = sum(cases),
              deaths = sum(deaths),
              hospitalizations = sum(hospitalizations))</code></pre>
<p>We also want a lag-column. That is, for each date, we want the count from the day preceding it. This allows us to compute the change for each day.</p>
<p>We also add a new column <code>weekday</code>, which computes the day of the week. This allows us to visualize weekly periodic fluctuations in reporting. We might not know the cause of such noise in the data set, but it is still important to show patterns when they occur.</p>
<pre class="r"><code># Create a lag column for cases
country &lt;- country %&gt;% mutate(previous_cases = lag(cases, order_by=date),
                              weekday = lubridate::wday(date, label=TRUE))</code></pre>
<div id="country-wide-visualizations" class="section level3">
<h3>Country-wide visualizations</h3>
<p>At this point, we have readied our data, and can start plotting. First, lets plot the number of cases we have in Denmark, and supply a trend-line for the cases</p>
<p>(<em>Aside:</em> We use ggplot2 to visualize. ggplot uses a <em>grammar</em> of graphical layers as its plotting strategy. For instance <code>p + geom_point()</code> is a form of “addition” where <code>p</code> is a plot and <code>geom_point()</code> is an x-y scatterplot of points. So the <code>+</code> means “add another layer on top of our plot.”</p>
<p>The other key idea is that of the <code>aes(..)</code> function. This is an <em>aesthetic</em>-mapping. For example, the expression <code>aes(x=date, y=cases)</code> maps the <code>date</code> column to the x-axis, and the <code>cases</code> column to the y-axis. Likewise, <code>aes(color = weekday)</code> maps a tables <code>weekday</code> column into a “color dimension.”)</p>
<p>The trend-line is computed by <a href="https://en.wikipedia.org/wiki/Local_regression">Local Regression</a>, or LOESS (LOcally Estimated Scatterplot Smoothing). This is a generalization of a moving average over the data. The <code>span = .3</code> parameter sets the bandwidth to 30% of the data.</p>
<p>LOESS is a trade-off where we throw computational power at the problem to obtain good smoothed trend lines. It would be impossible to do by hand, but we have access to modern computers with ample computational power.</p>
<pre class="r"><code>plot_country &lt;- function(p, title, caption) {
    p + geom_point(aes(color = weekday), size=2) +
        geom_smooth(method = &#39;loess&#39;, span = .3) +
        scale_colour_brewer(palette=&quot;Set2&quot;) +
        labs(title = title, caption = caption)
}

p &lt;- ggplot(country, aes(x=date, y=cases))
plot_country(p, &quot;Trendline for Covid-19 cases in Denmark&quot;, &quot;Source: ssi.dk&quot;)</code></pre>
<pre><code>## `geom_smooth()` using formula &#39;y ~ x&#39;</code></pre>
<p><img src="index_files/figure-html/country-cases-1.png" width="672" /></p>
<p>We can use the same plot function to handle hospitalizations in Denmark</p>
<pre class="r"><code>p &lt;- ggplot(country, aes(x=date, y=hospitalizations))
plot_country(p, &quot;Trendline for Covid-19: new hospitalizations in Denmark&quot;, &quot;Source: ssi.dk&quot;)</code></pre>
<pre><code>## `geom_smooth()` using formula &#39;y ~ x&#39;</code></pre>
<p><img src="index_files/figure-html/country-hospitalizations-1.png" width="672" /></p>
<p>And likewise for deaths. Since deaths tend to have a larger lag before reporting, we don’t report the last 6 days</p>
<pre class="r"><code>hi_cutoff_deaths &lt;- max(country$date) - days(6)
p &lt;- ggplot(country %&gt;% filter(date &lt; hi_cutoff_deaths), aes(x=date, y=deaths))
plot_country(p, &quot;Trendline for Covid-19: new deaths in Denmark&quot;, &quot;Source: ssi.dk&quot;)</code></pre>
<pre><code>## `geom_smooth()` using formula &#39;y ~ x&#39;</code></pre>
<p><img src="index_files/figure-html/country-deaths-1.png" width="672" /></p>
<p>The next plot computes the <em>change</em> from the day before to the next day. A positive number means “There were this many more cases today.” A negative number means “There were this fewer cases today.” This shows how data is getting more noisy once Omicron takes over and more tests are being made.</p>
<p>As we shall see, this noise mostly comes from a single region in Denmark.</p>
<pre class="r"><code># Lagged data computes the difference to the day before.
plot_country_lag &lt;- function(p, title, caption) {
    p + geom_point(size=1.5) +
        scale_colour_brewer(palette=&quot;Set2&quot;) +
        labs(title = title, caption = caption)
}

p &lt;- ggplot(country, aes(x=date, y=(cases - previous_cases), color=weekday))
plot_country_lag(p, &quot;As Omicron took over, noise entered data in Denmark&quot;, &quot;Source: ssi.dk&quot;)</code></pre>
<pre><code>## Warning: Removed 1 rows containing missing values (geom_point).</code></pre>
<p><img src="index_files/figure-html/country-lagged-1.png" width="672" /></p>
<p>Another way of plotting this is to plot the number of cases today on one axis, and the previous cases from the day before on another axis.</p>
<pre class="r"><code>p &lt;- ggplot(country, aes(x=previous_cases, y=cases, color=weekday))
plot_country_lag(p, &quot;Delta change on cases&quot;, &quot;Source: ssi.dk&quot;) +
  geom_abline(slope=1, color=&#39;gray&#39;, linetype=2)</code></pre>
<pre><code>## Warning: Removed 1 rows containing missing values (geom_point).</code></pre>
<p><img src="index_files/figure-html/country-lagged-scatter-1.png" width="672" /></p>
<p>The fact Monday and Sunday are always above the dashed line means they always provide an increase in case count compared to other days. The days where these numbers tend to be entered into the database are Monday and Tuesday.</p>
<p>Because there are some clear day-of-week structure in the data set, it’s worth looking a bit into this. In particular:</p>
<ul>
<li><code>Monday</code> tends to have large positive change.</li>
<li><code>Wednesday</code> tend to have a smaller decrease.</li>
</ul>
<pre class="r"><code>plot_day_of_week &lt;- function(p, title, caption) {
    p + scale_colour_brewer(palette=&quot;Set2&quot;) +
        stat_boxplot(aes(color=weekday), alpha=0.3) +
        labs(title = title, caption = caption)
}

p &lt;- ggplot(country, aes(x=weekday, y=(cases - previous_cases)))
plot_day_of_week(p, &quot;Some days of the week has clear over/under-representation&quot;, &quot;Source: ssi.dk&quot;)</code></pre>
<pre><code>## Warning: Removed 1 rows containing non-finite values (stat_boxplot).</code></pre>
<p><img src="index_files/figure-html/country-weekday-1.png" width="672" /></p>
</div>
</div>
<div id="regional-data" class="section level2">
<h2>Regional data</h2>
<p>Compute the aggregate over regions, rather than for the whole country</p>
<pre class="r"><code>regions &lt;- summary %&gt;%
  group_by(date, region) %&gt;%
  summarize(cases = sum(cases), deaths = sum(deaths), hospitalizations = sum(hospitalizations))</code></pre>
<pre><code>## `summarise()` has grouped output by &#39;date&#39;. You can override using the `.groups`
## argument.</code></pre>
<pre class="r"><code>regions &lt;- regions %&gt;% mutate(weekday = lubridate::wday(date, label=TRUE), order_by=date)</code></pre>
<div id="regional-visualizations" class="section level3">
<h3>Regional visualizations</h3>
<p>To visualize the regional data, we use a facet grid, splitting on region. As we see, there are a lot of noise data generated by “Hovedstaden” (corresponding to the general area around Copenhagen). This region is generating most cases, by far.</p>
<pre class="r"><code>plot_regions &lt;- function(p, title, subtitle) {
    p + geom_point(aes(color=region), size=.5) +
        facet_grid(rows=vars(region)) +
        scale_colour_brewer(palette=&quot;Set2&quot;) +
        labs(title = title,
             subtitle = subtitle,
             caption = &quot;Source: ssi.dk&quot;,
             x = &quot;Date&quot;,
             y = &quot;Detected Cases&quot;)
}

p &lt;- ggplot(regions, aes(x=date, y=cases))
plot_regions(p, &quot;Regional split of cases, DK&quot;,
                &quot;These numbers are somewhat dodgy because of changes in test strategy&quot;)</code></pre>
<p><img src="index_files/figure-html/regional-cases-1.png" width="672" /></p>
<p>We can also visualize regional new hospitalizations and deaths:</p>
<pre class="r"><code>p &lt;- ggplot(regions, aes(x=date, y=hospitalizations))
p + geom_point(aes(color=region), size=.5) +
    facet_grid(rows=vars(region)) +
    scale_colour_brewer(palette=&quot;Set2&quot;) +
    labs(title = &quot;Regional split of Hospitalizations, DK&quot;,
         subtitle = &quot;Data provides an upper bound on the actual hospitalization count&quot;,
         caption = &quot;Source: ssi.dk&quot;,
         x = &quot;Date&quot;,
         y = &quot;New Hospitalizations&quot;)</code></pre>
<p><img src="index_files/figure-html/regional-hospitalizations-1.png" width="672" /></p>
<pre class="r"><code>p &lt;- ggplot(regions, aes(x=date, y=deaths))
p + geom_point(aes(color=region), size=.5) +
    facet_grid(rows=vars(region)) +
    scale_colour_brewer(palette=&quot;Set2&quot;) +
    labs(title = &quot;Regional split of Deaths, DK&quot;,
         subtitle = &quot;Data provides an upper bound on the actual death count&quot;,
         caption = &quot;Source: ssi.dk&quot;,
         x = &quot;Date&quot;,
         y = &quot;New Deaths&quot;)</code></pre>
<p><img src="index_files/figure-html/regional-deaths-1.png" width="672" /></p>
</div>
</div>
<div id="weekly-data" class="section level2">
<h2>Weekly data</h2>
<p>As with the case for daily key figures, we can also use the weekly key figures. An important point of this data set is that the <code>ageGroup</code> are not a continous variable, but a discrete set of groups, non-uniformly spaced in between:</p>
<pre class="r"><code>levels(factor(weekly$ageGroup))</code></pre>
<pre><code>## [1] &quot;00-02&quot; &quot;03-05&quot; &quot;06-11&quot; &quot;12-15&quot; &quot;16-19&quot; &quot;20-39&quot; &quot;40-64&quot; &quot;65-79&quot; &quot;80+&quot;</code></pre>
<p>Why this is so is a good question. My bet is that it captures schooling groups among the youngest, splits adults into younger and older adults pivoting on 40, and handles the elderly in two large groups as well. However, it also means direct comparison between groups is somewhat dangerous.</p>
<div id="visualizations" class="section level3">
<h3>Visualizations</h3>
<p>We can provide a simple raster plot, where <code>x</code> represents the week, <code>y</code> represents the (discrete) age group and the fill represents the count we are interested in. In principle, the age groups have different sizes, but we can adjust for the size difference in groups by looking at “x per 100.000”.</p>
<pre class="r"><code>plot_age_cases &lt;- function(p, title, subtitle) {
    p + geom_tile() +
        scale_fill_continuous(type = &quot;viridis&quot;) +
        labs(title = title, subtitle = subtitle, caption = &quot;Source: ssi.dk&quot;, x=&quot;Week&quot;, y = &quot;Age Group&quot;)
}</code></pre>
<p>The above function allows us to plot cases per age group, and tested per age group</p>
<pre class="r"><code>p &lt;- ggplot(weekly, aes(x=week, y=ageGroup, fill=cases_100k, height=0.8))
plot_age_cases(p, &quot;Weekly cases split per age group, DK&quot;, &quot;Schools were closed on 15th Dec 2021, reopened in Jan 2022&quot;)</code></pre>
<p><img src="index_files/figure-html/age-group-cases-1.png" width="672" /></p>
<pre class="r"><code>p &lt;- ggplot(weekly, aes(x=week, y=ageGroup, fill=tested_100k, height=0.8))
plot_age_cases(p, &quot;Weekly tests split per age group, DK&quot;, &quot;Schools were closed on 15th Dec 2021, reopened in Jan 2022&quot;)</code></pre>
<p><img src="index_files/figure-html/age-group-tests-1.png" width="672" /></p>
</div>
</div>
<div id="muncipality-data" class="section level2">
<h2>Muncipality data</h2>
<p>To compute incidence, we first compute a z-value as the difference from the mean. This sets us up for a label which are either above or below the mean value.</p>
<pre class="r"><code>muncipalities$incidence_z &lt;- round(muncipalities$incidence - mean(muncipalities$incidence), 2)
muncipalities$incidence_type &lt;- ifelse(muncipalities$incidence_z &lt; 0, &quot;Below mean&quot;, &quot;Above mean&quot;)</code></pre>
<p>Reorder the muncipality factor levels according to the incidence score, then plot a diverging bars plot for the data.</p>
<pre class="r"><code>ggplot(muncipalities %&gt;% mutate(name = fct_reorder(name, incidence_z)), aes(x=name, y=incidence)) +
  geom_bar(stat=&#39;identity&#39;, aes(fill=incidence_type), width=.5)  +
  scale_colour_brewer(palette=&quot;Set2&quot;) +
  geom_hline(yintercept=mean(muncipalities$incidence), linetype=2) +
  labs(subtitle=&quot;Incidence&quot;,
       title= &quot;Diverging Bars&quot;,
       fill = &quot;Incidence&quot;,
       x = &quot;Name&quot;,
       y = &quot;Incidence over the last 7 days&quot;,
       caption = &quot;Source: ssi.dk&quot;) +
  coord_flip()</code></pre>
<p><img src="index_files/figure-html/muncipality-incidence-overview-1.png" width="672" /></p>
<p>More computation allows us to do the same for cases per test</p>
<pre class="r"><code>muncipalities$rate &lt;- muncipalities$cases / muncipalities$tested_1w
muncipalities$rate_z &lt;- round(muncipalities$rate - mean(muncipalities$rate), 5)
muncipalities$rate_type &lt;- ifelse(muncipalities$rate_z &lt; 0, &quot;Below mean&quot;, &quot;Above mean&quot;)
muncipalities$rate</code></pre>
<pre><code>##  [1] 0.0000000 0.2297025 0.2569498 0.2380013 0.1919957 0.2219512 0.2477236
##  [8] 0.2389097 0.1938552 0.2224148 0.2124814 0.2166499 0.1961276 0.2699900
## [15] 0.2192586 0.1650718 0.2308020 0.2000000 0.2631820 0.2472989 0.2310406
## [22] 0.2413574 0.2389477 0.2468588 0.2496811 0.2739828 0.2806822 0.2495310
## [29] 0.2619624 0.2610504 0.2756871 0.2699681 0.2492594 0.3049918 0.2838725
## [36] 0.2809195 0.3349118 0.3147268 0.2492857 0.2631126 0.3033233 0.2591864
## [43] 0.2126210 0.2601593 0.2419920 0.2800462 0.2589862 0.2946809 0.3611765
## [50] 0.3344401 0.3172257 0.2694737 0.2659446 0.2843137 0.3202247 0.3437908
## [57] 0.3528529 0.3068381 0.3220339 0.2630290 0.3159521 0.3349705 0.2948207
## [64] 0.3686604 0.3645694 0.2791487 0.2768087 0.3476342 0.3148337 0.3235547
## [71] 0.3509985 0.3275252 0.4154663 0.3600289 0.3208923 0.3719893 0.3334413
## [78] 0.3312846 0.3384451 0.3390210 0.4325843 0.3397401 0.3153484 0.3599222
## [85] 0.3918379 0.3522484 0.3478261 0.3620302 0.3635526 0.3470290 0.3505386
## [92] 0.3366683 0.3276776 0.2584270 0.3587553 0.3523768 0.3610354 0.3180609
## [99] 0.3342161</code></pre>
<pre class="r"><code>ggplot(muncipalities %&gt;% mutate(name = fct_reorder(name, rate)), aes(x=name, y=rate)) +
  geom_bar(stat=&#39;identity&#39;, aes(fill=rate_type), width=.5)  +
  scale_colour_brewer(palette=&quot;Set2&quot;) +
  geom_hline(yintercept=mean(muncipalities$rate), linetype=2) +
  labs(title= &quot;Diverging Bars Plot, DK&quot;,
       subtitle = &quot;Cases/Tested ratio over the last 7 days&quot;,
       fill = &quot;rate&quot;,
       x = &quot;Name&quot;,
       y = &quot;Rate&quot;,
       caption = &quot;Source: ssi.dk&quot;) +
  coord_flip()</code></pre>
<p><img src="index_files/figure-html/muncipality-rate-overview-1.png" width="672" /></p>
<div id="analyzing-infections-over-population-counts" class="section level3">
<h3>Analyzing infections over population counts</h3>
<p>Read in Popcount. These can be obtained by Danmarks Statistik, by query on <code>FOLK1AM</code> in their data bank:</p>
<pre class="r"><code>read_data_2 &lt;- function(f) {
    raw &lt;- readBin(f, &quot;raw&quot;, n = file.size(f))
    x_utf8 &lt;- iconv(list(raw), from = &quot;ISO-8859-1&quot;, to = &quot;UTF-8&quot;, toRaw = TRUE)[[1]]

    # CSV variant 2 uses ; as the separator, among other adaptations
    res &lt;- readr::read_csv2(x_utf8, col_names=FALSE)
    return(res)
}

popcount &lt;- read_data_2(&quot;./data/DS/2022121185617360647690FOLK1AM68563293012.csv&quot;)</code></pre>
<pre><code>## ℹ Using &quot;&#39;,&#39;&quot; as decimal and &quot;&#39;.&#39;&quot; as grouping mark. Use `read_delim()` for more control.</code></pre>
<pre><code>## Rows: 103 Columns: 4
## ── Column specification ────────────────────────────────────────────────────────────────────────
## Delimiter: &quot;;&quot;
## chr (3): X1, X2, X3
## dbl (1): X4
## 
## ℹ Use `spec()` to retrieve the full column specification for this data.
## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.</code></pre>
<pre class="r"><code>popcount &lt;- popcount %&gt;% rename(name = 3, popcount = 4)
popcount &lt;- popcount %&gt;% select(name, popcount)
popcount</code></pre>
<pre><code>## # A tibble: 103 × 2
##    name          popcount
##    &lt;chr&gt;            &lt;dbl&gt;
##  1 København       644987
##  2 Frederiksberg   103963
##  3 Dragør           14602
##  4 Tårnby           42728
##  5 Albertslund      27575
##  6 Ballerup         49228
##  7 Brøndby          35535
##  8 Gentofte         74154
##  9 Gladsaxe         69321
## 10 Glostrup         23519
## # … with 93 more rows</code></pre>
<p>Join the tables, which will happen on the muncipality name. I would have liked a better key for the join, but this will do:</p>
<pre class="r"><code>muncipalities &lt;- muncipalities %&gt;% left_join(popcount)</code></pre>
<pre><code>## Joining, by = &quot;name&quot;</code></pre>
<pre class="r"><code>muncipalities %&gt;% select(name, incidence, popcount)</code></pre>
<pre><code>## # A tibble: 99 × 3
##    name            incidence popcount
##    &lt;chr&gt;               &lt;dbl&gt;    &lt;dbl&gt;
##  1 &quot;&quot;                     0        NA
##  2 &quot;København&quot;         1120    644987
##  3 &quot;Frederiksberg&quot;     1289    103963
##  4 &quot;Ballerup&quot;          1469     49228
##  5 &quot;Brøndby&quot;            995.    35535
##  6 &quot;Dragør&quot;            1249     14602
##  7 &quot;Gentofte&quot;          1251     74154
##  8 &quot;Gladsaxe&quot;          1293     69321
##  9 &quot;Glostrup&quot;          1131     23519
## 10 &quot;Herlev&quot;            1337     28861
## # … with 89 more rows</code></pre>
<p>Now, test correlation via Pearson:</p>
<pre class="r"><code>plot(muncipalities$incidence, muncipalities$popcount)</code></pre>
<p><img src="index_files/figure-html/correlation-popcount-incidence-1.png" width="672" /></p>
<pre class="r"><code>cor.test(muncipalities$incidence, muncipalities$popcount)</code></pre>
<pre><code>## 
##  Pearson&#39;s product-moment correlation
## 
## data:  muncipalities$incidence and muncipalities$popcount
## t = -1.5399, df = 92, p-value = 0.127
## alternative hypothesis: true correlation is not equal to 0
## 95 percent confidence interval:
##  -0.3498924  0.0455674
## sample estimates:
##        cor 
## -0.1585131</code></pre>
<p>Clearly, this argues there are no strong connection between population count, and the incidence in a given muncipality.</p>
<p>Analyzing the rate shows there’s a connection between it and incidence, but this is more expected:</p>
<pre class="r"><code>pairs(muncipalities %&gt;% select(incidence,popcount,rate))</code></pre>
<p><img src="index_files/figure-html/correlation-incidence-rate-1.png" width="672" /></p>
<pre class="r"><code>cor.test(muncipalities$incidence, muncipalities$rate)</code></pre>
<pre><code>## 
##  Pearson&#39;s product-moment correlation
## 
## data:  muncipalities$incidence and muncipalities$rate
## t = 13.767, df = 97, p-value &lt; 2.2e-16
## alternative hypothesis: true correlation is not equal to 0
## 95 percent confidence interval:
##  0.7336920 0.8708902
## sample estimates:
##       cor 
## 0.8133051</code></pre>
<p>Summarize:</p>
<pre class="r"><code>summary(muncipalities$rate)</code></pre>
<pre><code>##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
##  0.0000  0.2494  0.2843  0.2909  0.3376  0.4326</code></pre>
<pre class="r"><code>d &lt;- density(muncipalities$rate)
plot(d)</code></pre>
<p><img src="index_files/figure-html/muncipality-summary-1.png" width="672" /></p>
</div>
</div>




</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open');
  });
});
</script>

<!-- code folding -->


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
